// 4x4 grid
// from Littman, Cassandra and Kaelbling
// Learning policies for partially observable environments: Scaling up  
// Technical Report CS, Brown University


dtmc

const int CMAX;
const double THRESHOLD;

const int M01;
const int M11;
const int M21;
const int P01;
const int P11;
const int P21;

module countermodule
    c : [0..CMAX] init 0;
    [p] true -> (c'=min(c+1,CMAX));
endmodule

module strategy 
    pick : [0..4];
    mem : [0..2];
    [p] pick = 0 & mem = 0 & o = 1 -> (mem' = M01) & (pick' = P01);
    [p] pick = 0 & mem = 1 & o = 1 -> (mem' = M11) & (pick' = P11);
    [p] pick = 0 & mem = 2 & o = 1 -> (mem' = M21) & (pick' = P21);
    
    [done] pick = 0 & o = 2 -> true;
    
    [north] pick = 1 -> (pick' = 0);
    [east] pick = 2 -> (pick' = 0);
    [south] pick = 3 -> (pick' = 0);
    [west] pick = 4 -> (pick' = 0);
endmodule

module grid
	x : [0..3]; // x coordinate
	y : [0..3]; // y coordinate
	o : [0..2]; // observables
	// 0 - initial observation
	// 1 - in the grid (not target)
	// 2 - observe target
		
	// initially randomly placed within the grid (not at the target)
	[] o=0 -> 1/15 : (o'=1) & (x'=0) & (y'=0)
			+ 1/15 : (o'=1) & (x'=0) & (y'=1)
			+ 1/15 : (o'=1) & (x'=0) & (y'=2)
			+ 1/15 : (o'=1) & (x'=0) & (y'=3)
			+ 1/15 : (o'=1) & (x'=1) & (y'=0)
			+ 1/15 : (o'=1) & (x'=1) & (y'=1)
			+ 1/15 : (o'=1) & (x'=1) & (y'=2)
			+ 1/15 : (o'=1) & (x'=1) & (y'=3)	
			+ 1/15 : (o'=1) & (x'=2) & (y'=0)
			+ 1/15 : (o'=1) & (x'=2) & (y'=1)
			+ 1/15 : (o'=1) & (x'=2) & (y'=2)
			+ 1/15 : (o'=1) & (x'=2) & (y'=3)
			// + 1/15 : (o'=1) & (x'=3) & (y'=0) this is the traget
			+ 1/15 : (o'=1) & (x'=3) & (y'=1)
			+ 1/15 : (o'=1) & (x'=3) & (y'=2)
			+ 1/15 : (o'=1) & (x'=3) & (y'=3);
			
	// move around the grid
	[east] o=1 & !(x=2 & y=0) -> 0.9: (x'=min(x+1,3)) + 0.1: true; // not reached target
	[east] o=1 & x=2 & y=0 -> 0.9: (x'=min(x+1,3)) & (o'=2) + 0.1: true; // reached target
	[west] o=1 -> 0.9: (x'=max(x-1,0)) + 0.1: true; // not reached target
	[north] o=1 -> 0.9: (y'=min(y+1,3)) + 0.1: true; // reached target
	[south] o=1 & !(x=3 & y=1) -> 0.4: (y'=max(y-1,0)) + 0.6: true; // not reached target
	[south] o=1 & x=3 & y=1 -> 0.4: (y'=max(y-1,0)) & (o'=2) + 0.6: true; // reached target
	
	// reached target
	[done] o=2 -> true;
	
endmodule

// reward structure for number of steps to reach the target
rewards "steps"
    [p] o = 1: 1;
endrewards

// target observation
label "goal" = o=2;
