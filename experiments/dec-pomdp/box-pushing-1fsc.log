2024-05-16 22:56:27,353 - cli.py - This is Paynt version 0.1.0.
2024-05-16 22:56:27,353 - sketch.py - loading sketch from models/archive/jair24-synthesis/dec-pomdp/box-pushing-1fsc/sketch.templ ...
2024-05-16 22:56:27,353 - sketch.py - assuming sketch in PRISM format...
2024-05-16 22:56:27,521 - prism_parser.py - PRISM model type: DTMC
2024-05-16 22:56:27,521 - prism_parser.py - processing hole definitions...
2024-05-16 22:56:27,528 - prism_parser.py - loading properties from models/archive/jair24-synthesis/dec-pomdp/box-pushing-1fsc/sketch.props ...
2024-05-16 22:56:27,531 - prism_parser.py - found the following specification: optimality: R[exp]{"moves"}max=? [F "goal"] 
2024-05-16 22:56:27,531 - jani.py - constructing JANI program...
2024-05-16 22:56:27,684 - jani.py - constructing the quotient...
2024-05-16 22:56:29,176 - jani.py - associating choices of the quotient with hole assignments...
2024-05-16 22:56:29,209 - sketch.py - sketch parsing OK
2024-05-16 22:56:29,209 - sketch.py - converting state rewards 'moves' to state-action rewards
2024-05-16 22:56:29,213 - sketch.py - constructed explicit quotient having 5220 states and 29730 actions
2024-05-16 22:56:29,214 - sketch.py - found the following specification optimality: R[exp]{"moves"}max=? [F "goal"] 
2024-05-16 22:56:29,242 - synthesizer.py - synthesis initiated, design space: 1e6
2024-05-16 22:56:30,007 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-05-16 22:56:30,007 - synthesizer.py - M1_0_e=0, M1_0_w=0, M1_0_o=0, M1_0_s=0, M1_0_l=0, M1_1_e=0, M1_1_w=0, M1_1_o=0, M1_1_s=0, M1_1_l=0, P1_0_e=2, P1_0_w=0, P1_0_o=0, P1_0_s=2, P1_0_l=2, P1_1_e=3, P1_1_w=3, P1_1_o=3, P1_1_s=3, P1_1_l=3, M2_0_e=0, M2_0_w=0, M2_0_o=0, M2_0_s=0, M2_0_l=0, M2_1_e=0, M2_1_w=0, M2_1_o=0, M2_1_s=0, M2_1_l=0, P2_0_e=2, P2_0_w=0, P2_0_o=1, P2_0_s=2, P2_0_l=2, P2_1_e=3, P2_1_w=3, P2_1_o=3, P2_1_s=3, P2_1_l=3
2024-05-16 22:56:30,008 - synthesizer.py - double-checking specification satisfiability:  : 183.12202550415012
--------------------
Synthesis summary:
optimality objective: R[exp]{"moves"}max=? [F "goal"] 

method: AR, synthesis time: 0.76 s
number of holes: 40, family size: 1e6, quotient: 5220 states / 29730 actions
explored: 100 %
MDP stats: avg MDP size: 2035, iterations: 105

optimum: 183.122026
--------------------
